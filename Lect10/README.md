## DL4ES, Лекция 10

#### Роль начального приближения в оптимизации глубоких нейросетей. Дисперсия карт активаций.



Лекция посвящена важности начального приближения значений параметров в оптимизации глубоких нейросетей и влиянию начального приближения на дисперсию карт активаций.

Обсуждается, как неправильная инициализация может привести к неэффективному обучению или его полному отсутствию, а также к нежелательным эффектам, таким как константные или случайные ответы сети.

В лекции рассматривается модельная ситуация с полносвязной нейросетью и гиперболическим тангенсом в качестве функции активации. Подчеркивается, что для поддержания стабильности дисперсии активаций между слоями необходимо правильно устанавливать дисперсию параметров при инициализации весов нейросети, что ведет к выводу формулы для дисперсии параметров, исходя из размерности входных данных слоя.

Обсуждение включает в себя анализ влияния различных способов инициализации на процесс обучения и представляет основу для выбора метода инициализации параметров для эффективного обучения глубоких нейросетей.



В качестве материалов на дополнительное чтение можно обратить внимание на следующие источники:

[Веб-страница](https://www.deeplearning.ai/ai-notes/initialization/index.html) с визуализацией свойств процесса обучения полносвязной нейросети для различных модельных двумерных задач при различных начальных приближениях для параметров.

