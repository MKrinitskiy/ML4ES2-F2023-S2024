## DL4ES, Лекция 14

#### Пакетная нормализация, Прореживание, вопросы потребления памяти



Лекция посвящена теме стабилизации обучения искусственных нейронных сетей, в частности, методам пакетной нормализации (**Batch Normalization**) и прореживанию (**Dropout**).

Обсуждается проблема стабильности обучения, связанная со стагнацией процесса из-за потери информативности градиентов. Повторно рассматривается **пакетная нормализация** как способ ускорения и стабилизации обучения за счёт нормализации выходных данных слоев, что приводит к более равномерному распределению активаций и градиентов. Обсуждается потребление памяти при использовании пакетной нормализации.

Прореживание (**Dropout**) представлено как метод борьбы с переобучением и увеличением обобщающей способности сети путём случайного исключения части нейронов из процесса обучения, что имитирует обучение ансамбля сетей. Обсуждаются технические аспекты реализации **Dropout** и его влияние на процесс обучения и потребление памяти.
