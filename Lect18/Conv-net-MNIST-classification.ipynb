{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import Mish\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Tuple, List, Type, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(arr):\n",
    "    classes = np.unique(arr)\n",
    "    num_classes = len(classes)\n",
    "    return classes, np.squeeze(np.eye(num_classes)[arr.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def md5(fname):\n",
    "    import hashlib\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def show_progress(block_num, block_size, total_size):\n",
    "    print(round(block_num * block_size / total_size *100,2), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_hash = '84badc3964f15cbf97e9d0cba7f8e6d6'\n",
    "mnist_labels_hash = 'c17778ef9af07481b34bc3ca84d9b21a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('mnist_data.npy'):\n",
    "    print('downloading MNIST data:')\n",
    "    urllib.request.urlretrieve(\"https://ml4es.ru/links/mnist-data\", \"mnist_data.npy\", show_progress)\n",
    "downloaded_mnist_data_hash = md5('./mnist_data.npy')\n",
    "assert downloaded_mnist_data_hash == mnist_data_hash, 'Downloaded MNIST data is corrupt. Try downloading again.'\n",
    "print('MNIST data is valid')\n",
    "\n",
    "if not os.path.exists('mnist_labels.npy'):\n",
    "    print('downloading MNIST labels:')\n",
    "    urllib.request.urlretrieve(\"https://ml4es.ru/links/mnist-labels\", \"mnist_labels.npy\", show_progress)\n",
    "downloaded_mnist_labels_hash = md5('./mnist_labels.npy')\n",
    "assert downloaded_mnist_labels_hash == mnist_labels_hash, 'Downloaded MNIST labels is corrupt. Try downloading again.'\n",
    "print('MNIST labels are valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./mnist_data.npy')\n",
    "y = np.load('./mnist_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes,y = one_hot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 28, 28), (70000, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X/255.).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, X.shape[0], 1)\n",
    "random_digit = X[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(random_digit), cmap='gray')\n",
    "_ = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size = (28, 28),\n",
    "                 conv_channels: List[int] = [8, 32, 64],\n",
    "                 activation: Type[torch.nn.Module] = Mish):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        _conv_layers = []\n",
    "        curr_channels = 1\n",
    "        pool = torch.nn.MaxPool2d(kernel_size=(2,2))\n",
    "        act = activation()\n",
    "        \n",
    "        for hidden_channels in conv_channels:\n",
    "            conv = torch.nn.Conv2d(curr_channels,\n",
    "                                   hidden_channels,\n",
    "                                   kernel_size=(3,3),\n",
    "                                   stride=1,\n",
    "                                   padding=1,\n",
    "                                   padding_mode='zeros')\n",
    "            _conv_layers.append(conv)\n",
    "            _conv_layers.append(act)\n",
    "            _conv_layers.append(pool)\n",
    "            curr_channels = hidden_channels\n",
    "            \n",
    "        # 1  x 28x28 -> (conv) -> 8  x 28x28 -> (act) -> (pool) -> 8  x 14x14\n",
    "        # 8  x 14x14 -> (conv) -> 32 x 14x14 -> (act) -> (pool) -> 32 x 7x7\n",
    "        # 32 x 7x7   -> (conv) -> 64 x 7x7   -> (act) -> (pool) -> 64 x 3x3\n",
    "        \n",
    "        gap = torch.nn.AvgPool2d(kernel_size=(3,3))\n",
    "        # N x 64 x 3x3 -> (pool) -> N x 64 x 1x1\n",
    "        \n",
    "        _conv_layers.append(gap)\n",
    "        \n",
    "        _fc_layers = []\n",
    "        _fc_layers.append(torch.nn.Linear(64, 32))\n",
    "        _fc_layers.append(act)\n",
    "        _fc_layers.append(torch.nn.Linear(32, 16))\n",
    "        _fc_layers.append(act)\n",
    "        _fc_layers.append(torch.nn.Linear(16, 10))\n",
    "#         _fc_layers.append(act)\n",
    "#         _fc_layers.append(torch.nn.Identity())\n",
    "        \n",
    "        # N x 10\n",
    "        _fc_layers.append(torch.nn.Softmax(dim=-1))\n",
    "        \n",
    "        self._conv_layers = torch.nn.Sequential(*_conv_layers)\n",
    "        self._fc_layers = torch.nn.Sequential(*_fc_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self._conv_layers.forward(x)\n",
    "        x = torch.flatten(h, start_dim=1)\n",
    "        # N x 64 x 1x1 -> (flatten) -> N x 64\n",
    "        \n",
    "        out = self._fc_layers.forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (_conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Mish()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Mish()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): Mish()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): AvgPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0)\n",
      "  )\n",
      "  (_fc_layers): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): Mish()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Mish()\n",
      "    (4): Linear(in_features=16, out_features=10, bias=True)\n",
      "    (5): Softmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "Total number of trainable parameters 23690\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('Total number of trainable parameters', \n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer, \n",
    "                       loss_function: torch.nn.Module, \n",
    "                       data_loader: torch.utils.data.DataLoader,\n",
    "                       tb_writer: SummaryWriter,\n",
    "                       epoch: int,\n",
    "                       batch_size: int,\n",
    "                       epoch_size_batches: int):\n",
    "    train_loss = []\n",
    "    batch_averaged_loss = []\n",
    "    idx = 0\n",
    "    model.train()\n",
    "    while True:\n",
    "        (batch_data, batch_labels) = next(iter(data_loader))\n",
    "        optimizer.zero_grad()\n",
    "        data_gpu, labels_gpu = batch_data.cuda(), batch_labels.cuda()\n",
    "        output = model(data_gpu)\n",
    "        loss = loss_function(output, labels_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        idx = idx + 1\n",
    "        if idx >= epoch_size_batches:\n",
    "            break\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module, \n",
    "                          data_loader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            data_gpu, labels_gpu = data.cuda(), labels.cuda()\n",
    "            output = model(data_gpu)\n",
    "            test_loss += loss_function(output, labels_gpu).sum()\n",
    "\n",
    "    return {'loss': test_loss.item() / len(data_loader.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None, transform_labels = None):\n",
    "        self.X = X\n",
    "        self.transform = transform\n",
    "        self.Y = y\n",
    "        self.transform_labels = transform_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx, ...]\n",
    "        # X: N x 28x28\n",
    "        # x: 28x28\n",
    "        \n",
    "        x = x[np.newaxis,...]\n",
    "        # -> x: 1 x 28x28\n",
    "        \n",
    "        # DataLoader: 64 x 1x28x28\n",
    "        # data (x) : NxCxHxW\n",
    "        \n",
    "        y = self.Y[idx, ...]\n",
    "        # 10\n",
    "        # DataLoader: 10 -> Nx10\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.transform_labels:\n",
    "            y = self.transform_labels(y)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = CustomDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbatch, ybatch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ВНИМАНИЕ!!!\n",
    "\n",
    "обратить внимание на размерность мини-батча признакового описания объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbatch.shape\n",
    "\n",
    "# Соглашение в Pytorch: признаковое описание примеров поставляется в формате NCHW:\n",
    "# N - нумерует экземпляры (примеры) в подмножестве данных\n",
    "# C - количество цветовых каналов (признаков) во входных данных или в картах активаций\n",
    "# H - высота по пространственным размерностям - кол-во строк\n",
    "# W - ширина по пространственным размерностям - кол-во столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybatch_pred = model(xbatch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybatch_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0852, 0.1075, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0812, 0.1106, 0.0792, 0.1052, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0812, 0.1105, 0.0791, 0.1051, 0.0957, 0.1264,\n",
       "         0.0948],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0948],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0812, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0813, 0.1106, 0.0791, 0.1052, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1075, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0812, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1052, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1052, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1104, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0812, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1106, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1075, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0812, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0948],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0812, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1073, 0.1143, 0.0812, 0.1106, 0.0791, 0.1051, 0.0958, 0.1265,\n",
       "         0.0948],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0948],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1104, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1052, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0813, 0.1106, 0.0792, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0812, 0.1105, 0.0791, 0.1052, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1104, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1143, 0.0812, 0.1106, 0.0792, 0.1052, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1052, 0.0957, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0853, 0.1074, 0.1144, 0.0813, 0.1105, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1143, 0.0812, 0.1105, 0.0791, 0.1052, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1143, 0.0812, 0.1106, 0.0791, 0.1052, 0.0958, 0.1264,\n",
       "         0.0948],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1052, 0.0957, 0.1265,\n",
       "         0.0946],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0958, 0.1264,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1075, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1143, 0.0813, 0.1106, 0.0792, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947],\n",
       "        [0.0852, 0.1074, 0.1144, 0.0813, 0.1105, 0.0791, 0.1051, 0.0957, 0.1265,\n",
       "         0.0947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybatch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(ybatch_pred, ybatch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(run_name: str,\n",
    "                model: torch.nn.Module, \n",
    "                train_dataloader: torch.utils.data.DataLoader,\n",
    "                test_dataloader: torch.utils.data.DataLoader,\n",
    "                loss_function: torch.nn.Module = torch.nn.MSELoss(),\n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
    "                optimizer_params: Dict = {},\n",
    "                initial_lr = 0.001,\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                max_epochs = 1000,\n",
    "                early_stopping_patience = 10):\n",
    "    \n",
    "    #region TENSORBOARD tutorial\n",
    "    tb_writer = SummaryWriter(log_dir=f'./logs/{run_name}/')\n",
    "    #endregion ##############################\n",
    "    \n",
    "    #region borrowed from HW03\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "    \n",
    "    best_test_loss = None\n",
    "    best_epoch = None\n",
    "    \n",
    "    loss_history = []\n",
    "    #endregion borrowed from HW03\n",
    "    \n",
    "    pbar = tqdm(total=max_epochs)\n",
    "    for epoch in range(max_epochs):\n",
    "        train_epoch_loss_history = train_single_epoch(model,\n",
    "                                                      optimizer,\n",
    "                                                      loss_function,\n",
    "                                                      train_dataloader,\n",
    "                                                      tb_writer,\n",
    "                                                      epoch,\n",
    "                                                      batch_size=train_dataloader.batch_size,\n",
    "                                                      epoch_size_batches=156)\n",
    "        loss_history = loss_history + train_epoch_loss_history\n",
    "        test_metrics = validate_single_epoch(model,\n",
    "                                             loss_function,\n",
    "                                             test_dataloader)\n",
    "        \n",
    "        #region TENSORBOARD logging\n",
    "        tb_writer.add_scalar('train_loss',\n",
    "                             np.sum(train_epoch_loss_history)/len(train_dataloader.dataset),\n",
    "                             global_step=epoch)\n",
    "        tb_writer.add_scalar('val_loss', test_metrics['loss'], global_step=epoch)\n",
    "        #endregion ##############################\n",
    "        \n",
    "        lr_scheduler.step(test_metrics['loss'])\n",
    "        \n",
    "        if best_test_loss is None or best_test_loss > test_metrics['loss']:\n",
    "            best_test_loss = test_metrics['loss']\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, f'./best_model_{run_name}.pth')\n",
    "        \n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix(ordered_dict={'val_loss': test_metrics['loss']})\n",
    "        #endregion ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:13<00:00,  1.33s/it, val_loss=0.0254]\n"
     ]
    }
   ],
   "source": [
    "train_model('run002',\n",
    "            model, \n",
    "            train_dataloader = train_dataloader,\n",
    "            test_dataloader = val_dataloader,\n",
    "            loss_function=torch.nn.CrossEntropyLoss(), \n",
    "            initial_lr=0.0001,\n",
    "            max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применим нейросеть на одном подмножестве (mini-batch) данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prime = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2304e-06, 2.9454e-10, 9.4713e-07, 1.4101e-14, 1.7952e-05, 2.5333e-08,\n",
       "        9.9995e-01, 1.1408e-18, 2.8187e-05, 3.2945e-21],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prime[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0257, dtype=torch.float64, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(y_prime, y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_class = torch.argmax(y_prime, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 6, 2, 6, 2, 1, 7, 1, 4, 3, 4, 1, 6, 5, 8, 8, 7, 0, 5, 8, 6, 5, 2, 6,\n",
       "        6, 4, 2, 5, 1, 8, 0, 6, 5, 2, 7, 2, 7, 8, 4, 8, 3, 6, 7, 1, 8, 1, 3, 2,\n",
       "        4, 5, 2, 4, 8, 2, 7, 2, 6, 0, 6, 2, 3, 3, 2, 3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 6, 2, 6, 2, 1, 7, 1, 9, 5, 4, 1, 6, 5, 8, 8, 7, 0, 5, 8, 6, 5, 2, 6,\n",
       "        6, 4, 2, 5, 1, 8, 0, 6, 5, 2, 9, 9, 9, 8, 9, 3, 3, 6, 7, 1, 8, 1, 3, 2,\n",
       "        9, 5, 2, 4, 9, 2, 9, 2, 6, 0, 6, 2, 1, 3, 2, 3])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_class = torch.argmax(y, dim=1)\n",
    "true_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8125)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true_class == output_class).sum()/true_class.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посчитаем долю верных ответов на всем валидационном подмножестве данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 506.20it/s]                                                                                                                                                                                         \n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "examples_num = 0\n",
    "model.eval()\n",
    "x_batches_test = []\n",
    "y_batches_test = []\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for x,y in tqdm(val_dataloader, total = len(val_dataset)//64):\n",
    "        x_batches_test.append(x.detach().cpu().numpy())\n",
    "        y_batches_test.append(y.detach().cpu().numpy())\n",
    "        x_gpu, y_gpu = x.cuda(), y.cuda()\n",
    "        output_gpu = model(x_gpu)\n",
    "        output_cpu = output_gpu.cpu()\n",
    "        predicted_class = torch.argmax(output_cpu, dim=1)\n",
    "        true_class = torch.argmax(y, dim=1)\n",
    "        correct = correct + ((true_class == predicted_class).sum()).cpu().detach().numpy()\n",
    "        examples_num = examples_num + float(x.shape[0])\n",
    "        test_loss += loss_function(output_gpu, y_gpu).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.02535987)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = test_loss/examples_num\n",
    "val_loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy = correct/examples_num\n",
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
